{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Класс, который в последствии добавляется в словарь для удобного выбора\n",
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature=None,\n",
    "        threshold=None,\n",
    "        childs=None,\n",
    "        # left = None,\n",
    "        # right = None,\n",
    "        value=None,\n",
    "        proba_value = None\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.childs = childs\n",
    "        self.value = value\n",
    "        # self.right = right\n",
    "        # self.left = left\n",
    "        self.proba_value = proba_value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "    \n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, classes, max_depth=10, min_samples=10):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        self.tree = None\n",
    "        self.classes = classes\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # self.classes = np.unique(y)\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "\n",
    "    def calck_unic(self, a: list):\n",
    "        keys = np.unique(a)\n",
    "        # return {key: a[a == key].shape[0] for key in keys}\n",
    "        return (a[a == key].shape[0] for key in keys), keys\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.travers_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return np.array([self.travers_proba_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def entropy(self, y: np.ndarray):\n",
    "        hist, _ = self.calck_unic(y)\n",
    "        n = y.shape[0]\n",
    "        # hist = {key: val / len(y) for key, val in hist.items()}\n",
    "        info = -np.sum(np.fromiter((val/n * np.log2(val/n) for val in hist), dtype=np.float64))\n",
    "\n",
    "        return info\n",
    "    \n",
    "    #======================================\n",
    "    def gini(self, y:np.ndarray):\n",
    "        uitems = self.calck_unic(y)\n",
    "        n = y.shape[0]\n",
    "        return 1 - np.sum(np.fromiter(((val/n)**2 for val in uitems), dtype=np.float64))\n",
    "    #======================================\n",
    "\n",
    "    def information_gain(self, X_column: list, y: list):\n",
    "        if np.unique(y).shape[0] == 1:\n",
    "            return 0\n",
    "\n",
    "        n = y.shape[0]\n",
    "        parent = self.entropy(y)\n",
    "        # print(\"point1\")\n",
    "        uitems, keys = self.calck_unic(X_column)\n",
    "        uitems = [i for i in uitems]\n",
    "        # print(\"point2\")\n",
    "        #======================================\n",
    "        # left_inds = np.argwhere(X_column <= threshold).flatten()\n",
    "        # right_inds = np.argwhere(X_column > threshold).flatten()\n",
    "        # # print(left_inds)\n",
    "        # # print(X_column.shape)\n",
    "        # # print(y.shape)\n",
    "        # gini_left = self.gini(y[left_inds])\n",
    "        # gini_right = self.gini(y[right_inds])\n",
    "        # gini_split = (len(left_inds) / n) * gini_left +  (len(right_inds) / n) * gini_right\n",
    "        # return gini_split, threshold\n",
    "        #====================================== \n",
    "        # print(X_column.shape, y.shape )\n",
    "        info_x = np.sum(\n",
    "            [uitems[i] / n * self.entropy(y[X_column == keys[i]]) for i in range(len(uitems))]\n",
    "        )\n",
    "        # print(\"point3\")\n",
    "        split_info = -np.sum(\n",
    "            [val / n * np.log2(val / n) for val in uitems if val > 0]\n",
    "        )\n",
    "        # print(\"point4\")\n",
    "        if split_info != 0:\n",
    "            return (parent - info_x) / split_info, keys\n",
    "        else:\n",
    "            return 0, keys\n",
    "\n",
    "    def most_common(self, y):\n",
    "        labels = np.unique(y)\n",
    "        vals, _ = self.calck_unic(y)\n",
    "        return labels[np.argmax(vals)]\n",
    "\n",
    "    def proba_val(self, y):\n",
    "        n = y.shape[0]\n",
    "        probas = np.zeros(self.classes.shape[0])\n",
    "        vals, keys = self.calck_unic(y)\n",
    "\n",
    "        probas[np.in1d(self.classes, keys)] = np.fromiter(vals, dtype=np.float64) / n\n",
    "        return probas\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        best_feature = None\n",
    "        best_gain = -1\n",
    "        # best_gini = 1000000\n",
    "        # uitems = []\n",
    "        for i in range(X.shape[1]):\n",
    "            #==============================================\n",
    "            # trasholds = np.random.choice(np.unique(X[:, i]), 10)\n",
    "            # print(\"new_i\")\n",
    "            # for trashold in trasholds:\n",
    "            #==============================================\n",
    "            # print(\"test1\")\n",
    "            gain, now_uitems = self.information_gain(X[:, i], y)\n",
    "            # print(\"test2\")\n",
    "            # print(gain)\n",
    "            if gain > best_gain:\n",
    "                # print(\"yep\")\n",
    "                best_gain = gain\n",
    "                best_feature = i\n",
    "                uitems = now_uitems\n",
    "\n",
    "        return best_feature, uitems\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        n_samples = X.shape[0]\n",
    "        n_labels = np.unique(y).shape[0]\n",
    "\n",
    "        if n_samples <= self.min_samples or depth >= self.max_depth or n_labels <= 1:\n",
    "            return Node(value=self.most_common(y), proba_value=self.proba_val(y))\n",
    "\n",
    "        best_feature, ukeys = self.best_split(X, y)\n",
    "        #==============================================\n",
    "        # best_feature, best_threshold = self.best_split(X, y)\n",
    "        # l_inds = np.argwhere(X[:, best_feature] <= best_threshold).flatten()\n",
    "        # r_inds = np.argwhere(X[:, best_feature] > best_threshold).flatten()\n",
    "        # # print(\"depth2:\", depth)\n",
    "        # if len(l_inds) == 0 or len(r_inds) == 0:\n",
    "        #     return Node(value=self.most_common(y), proba_valUe=self.proba_val(y))\n",
    "        \n",
    "        # # print(\"depth3:\", depth)\n",
    "        # left = self.grow_tree(X = X[l_inds], y = y[l_inds], depth = depth+1)\n",
    "        # right = self.grow_tree(X = X[r_inds], y = y[r_inds], depth = depth+1)\n",
    "\n",
    "        # return Node(best_feature, best_threshold, left, right)\n",
    "        #==============================================\n",
    "        # В словаре содержатся не словари, а Node По сути, словарь содержит ссылки на объекты, а нужен он для более удобной навигации.\n",
    "        childs = {\n",
    "            key: self.grow_tree(\n",
    "                X[X[:, best_feature] == key],\n",
    "                y[X[:, best_feature] == key],\n",
    "                depth=depth + 1,\n",
    "            )\n",
    "            for key in ukeys\n",
    "        }\n",
    "\n",
    "        return Node(best_feature, childs=childs)\n",
    "\n",
    "    #==============================================\n",
    "    # def travers_tree(self, x, tree):\n",
    "    #     if tree.is_leaf_node():\n",
    "    #         return tree.value\n",
    "        \n",
    "    #     return self.travers_tree(x, tree.left) if tree.threshold >= x[tree.feature] else self.travers_tree(x, tree.right)\n",
    "\n",
    "    # def travers_proba_tree(self, x, tree):\n",
    "    #     if tree.is_leaf_node():\n",
    "    #         # print(tree.proba_value)\n",
    "    #         return tree.proba_value\n",
    "        \n",
    "    #     return self.travers_proba_tree(x, tree.left) if tree.threshold >= x[tree.feature] else self.travers_proba_tree(x, tree.right)\n",
    "    #==============================================\n",
    "\n",
    "    def travers_tree(self, x, tree):\n",
    "        if tree.is_leaf_node():\n",
    "            return tree.value\n",
    "\n",
    "        return self.travers_tree(\n",
    "            x,\n",
    "            tree.childs.get(\n",
    "                x[tree.feature], tree.childs.get(list(tree.childs.keys())[0])\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def travers_proba_tree(self, x, tree):\n",
    "        if tree.is_leaf_node():\n",
    "            return tree.proba_value\n",
    "\n",
    "        return self.travers_proba_tree(\n",
    "            x,\n",
    "            tree.childs.get(\n",
    "                x[tree.feature], tree.childs.get(list(tree.childs.keys())[0])\n",
    "            ),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка данных\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "transform = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\n",
    "dataset[\"class\"] = dataset[\"class\"].apply(lambda x: transform[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data/X_train.csv\")\n",
    "data.drop(labels=\"measurement_number\", axis=1 , inplace=True)\n",
    "data = data.groupby(\"series_id\").agg(['mean', 'std', 'median'])\n",
    "data.columns = [f'{col}_{stat}' for col, stat in data.columns]\n",
    "data = data.reset_index()\n",
    "data.drop(labels=[\"series_id\",\"row_id_mean\",\"row_id_std\", \"row_id_median\"], axis=1 , inplace=True)\n",
    "data = data.round(2).to_numpy(dtype=np.float64)\n",
    "y = pd.read_csv(\"./Data/y_train.csv\")[\"group_id\"].to_numpy(dtype=np.int64)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "# print(np.unique(y_test))\n",
    "# data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46 13 15  0 69  0  3 25 66 18 18  7 13 60 38  7  4 23 23 35 20 22 59 46\n",
      " 43  6 40 45  1 53 64 22 55 38 33 44 15 59 23 53 48 51 33  6  7  9 68 15\n",
      " 41 21 23 68 60 19 34 49 44 38 32  3 13 51 51 53 33 65  6 33 10 59 22 12\n",
      " 33 43 60  5 22 20  1 13  1 60 34 69 51 70  8 20 29 23 51  0 11 60 20 43\n",
      " 37  8 20 28 16  4 68 53 18 53 53 38  8 15  0 14 15  7 18 10  6 16 22  9\n",
      "  6 12 43  4 59  9 16 31 70 13 20 16 34 68 35  4 68 32 16  4 68 28 27 28\n",
      " 15  8 59  4 40  4 60 53 66 10  0 34  7 38 31 43 16 31 33 13 51 28 53 65\n",
      " 12 43 16 35 35 23 68 46  0 29 53 55 14 68 46 13 14 49 55 18  8 10 15  3\n",
      " 31 53  3 51  2  0  1  7 70 53 45 68 48 18 18  0  1 69 53 52  7  4 42 16\n",
      " 71  8 45 48  3 22  9 53 21 22 53 38  3 68  6  8 14 42 48  6 26 41 47 68\n",
      " 61 15 32 19  6 48 37 12 31 51  3 68 20 20 10 56 15  6 40 33  1 53  6  3\n",
      " 44  0  0 70 53  6 38 16  0  7 11  0  7 22 19  0 31  3 68 41 39 29 33 69\n",
      "  3 14  3 18 32 62 32 33 13  6 59 22  3 15 69 18  8  7  6 66  0 39  8 51\n",
      " 48 15 53 51 53 62 10  8  1 72 22 39 38 45  0 39 10 39 57 36 55 72 21 39\n",
      " 35 49 35 15 68 34 72 56  4 44  9  7 33  0 15 51 48 49  9 53 20  9 34 28\n",
      " 38 15 29 37  9  7  0 45 11 66 13 13 38 29 46 33 35  1 14 14 53  4 38 15\n",
      " 70 18 12 45 13 25 51 44 51  1 46  1  9 62  4  9 43 45  1 62 22  7  7 16\n",
      " 45 51  1 51 47 46 51 13 69  1  7  1 18 13  1 39 12 69 29 10 18  1 41 48\n",
      "  4 21 32 35 14  1 15 72 21 33 15  7 55 51 14 44 53 34 28 46  6 15 14 70\n",
      "  8  4 33 53 10 51 33 49 48 44 15 20 29  2  1 53  9 51  6 56 10 27 18 10\n",
      " 45 42 20 51  8 38 37 68 13 63  1  8  0 16 35 72 41 28 43  8 38 12 62  3\n",
      " 71 53  8  7 72  9  0 22 25 44 16 15 24 18 21 39 25 70 11 65 53  0 53  6\n",
      " 16 35 62  6  7 41 34 68 70 68  9 51 51 65 65  1  0 39 51  7  3  8 28 51\n",
      "  3 46 16  0  8 19 18 13 44  7 18 18 13 51  1 42  7 12 18 25 38 39 18 25\n",
      " 47 32  7 15 35 69 13  9 47 60  3 60  9 51 70  0 23 10  3 12  3 41  1 48\n",
      "  0 15  9 14 12 13 10 35 41  4  7  4 14 51 20 69 59 69 32 15 45 18 38 15\n",
      "  9 53  1 55  9 10 62 23 32 65 11 29 10  3 53 25 46 13 44 72 15  9 45 35\n",
      "  7 66 39 29 23 38 53 70 15 40 15  6 21  1 39  4 33 23  4 71 15 31  0 32\n",
      " 33 54 43 61 51 62 20 37  1 66  7 11  0 16 53  1 32 22 51 13 60 53 16 53\n",
      " 68 15  4 51 10  9 32 60 47 44 48 47 21  7 69 53 53 29 48 37 13 11  3 51\n",
      " 53 40 60  1 41  6 12  8 25 12 39 28 53 51 45 71 68  6 23 10 18 12 20 55\n",
      " 55  4 15 22 53  8 10 14 10 15 51 15 60 37  5  6 38 10]\n",
      "0.4461942257217848\n"
     ]
    }
   ],
   "source": [
    "# X = dataset[dataset.columns[:-1]].to_numpy()[:]\n",
    "# y = dataset[\"class\"].to_numpy()\n",
    "\n",
    "# x_train, x_test, y_train1, y_test1 = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "clf = DecisionTree(max_depth=10)\n",
    "clf.fit(X_train, y_train.flatten())\n",
    "otv = clf.predict(X_test)\n",
    "print(otv)\n",
    "# print(y_test.flatten()-1)\n",
    "# print(X_test)\n",
    "print(f1_score(y_test.flatten(), otv, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees = 10, max_deep = 10, min_samples = 10):\n",
    "        self.trees = [0 for i in range(n_trees)]\n",
    "        self.tree_inds = [0 for i in range(n_trees)]\n",
    "        self.n_trees = n_trees\n",
    "        self.max_deep = max_deep\n",
    "        self.min_samples = min_samples\n",
    "        self.num_classes=None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # n_features = int(X.shape[1]**0.5+0.5)\n",
    "        n_features = X.shape[0]\n",
    "        self.num_classes = np.unique(y).shape[0]\n",
    "\n",
    "        for i in range(self.n_trees):\n",
    "            # clf = DecisionTree(max_depth=self.max_deep, min_samples=self.min_samples)\n",
    "            # inds =  np.random.choice(np.arange(X.shape[1]), n_features)\n",
    "            clf = DecisionTree(classes = np.arange(73), max_depth=self.max_deep, min_samples=self.min_samples)\n",
    "            inds =  np.random.choice(np.arange(X.shape[0] // 3), n_features, replace=True)\n",
    "            # clf.fit(X[:, inds], y)\n",
    "            # print(y)\n",
    "            clf.fit(X[inds], y[inds])\n",
    "            # print(clf.predict(x_test[:,inds ]))\n",
    "            self.trees[i] = clf\n",
    "            self.tree_inds[i] = inds\n",
    "    \n",
    "    def predict(self, X):\n",
    "        otv = np.zeros((X.shape[0], self.num_classes))\n",
    "        \n",
    "        for i, clf in enumerate(self.trees):\n",
    "            # otv[np.arange(X.shape[0]), clf.predict(X[:, self.tree_inds[i]])] += 1\n",
    "            otv[np.arange(X.shape[0]), clf.predict(X)] += 1\n",
    "            # print(otv)\n",
    "        # print(otv)\n",
    "        return np.argmax(otv, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        otv = np.zeros((X.shape[0], self.num_classes))\n",
    "        for i, clf in enumerate(self.trees):\n",
    "            # print(clf.predict_proba(X))\n",
    "            # otv += clf.predict_proba(X[:, self.tree_inds[i]])\n",
    "\n",
    "            otv += clf.predict_proba(X)\n",
    "        return otv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61 39 34 61 56  0 46 25 66 18 18 31 34 66 40  7  4 24 23 19 20 22 59 72\n",
      " 20 46 53 46 11 48 64 22 71 43 33 44 15 59 54 53 53 71 33  6  2  9 68 72\n",
      " 47 21 54 22 60 19 53 49 44 38 68 26 12 10 60 53 35 45 46 33 39 53 22 62\n",
      " 35 43 60 53  2 20 57 13 11 60 15 56 71 70 33 20 29 54 60 61  9 60 65 20\n",
      " 69  8 20  8 45 41 49 53 18 63 53 46 44 23  0 55 55 10 18 65 46 46 22  9\n",
      "  6 12 60  4 53 21 45 31 70 13 46 62 34 68 35 53 68 20 20  4 68  8 27  8\n",
      " 72  8 59  4 44 11 60 53 66 72  0 34 55 40 31 43 62 10 33 34 60  8 48 45\n",
      " 12 43 16 69 35 23 68 46 32 29 53 71 14 22 18 13 52 49 10 18 57 15 65 46\n",
      " 31 48 46 66  2  0 57 65 70 53 62  0 64 40 43  0 57 69 64 52 16  4 38 20\n",
      " 71  8 16 53 43 22  9 53 21 22 53 38  3 49 53 33 53 42 53  6 46 47 57  0\n",
      " 22 15 32 53 46 53 37 12 10 51 18 68 20 20 60 21 15 18 65 33 57 48 46 46\n",
      " 42  0 20 70 53  6 72 62  0 31  9  0 10 68 19  0 31 40  0 41 70 29 33 69\n",
      " 29 19 46 18 32 65 32 35 13  6 59 22 46 53 69 18  8 51 29 71 22 39 43 72\n",
      " 53 25  8  7 48 13 31 16 18 72 22 48  8 49 32 39 39  8 44 36 55 72 21 70\n",
      " 25 42 35 25 68 34 72 21 53 45 21 10 33  0 15 51 15 13  9 53 46 21 34  8\n",
      " 35 72 29 69 42  7  0 62 11 60 49 46 38 29 46 35 35  9 53 55 48  4 38 15\n",
      " 70 40 20 45 13 25 71  9 71  1 35  9 21 12  4  9 43 16  9 62 10 10 49 65\n",
      " 46 71 42 72 57  6 71 46 56 57  7 57 18 60 57 18 62 69 44 15 18 57 11 53\n",
      "  4 21 32 35 14 57 15 72 21 33 72 65 71 71 53 44 15 34  8 46  6 15 14 70\n",
      " 27  4 33 64 10 71 33 23 48 35 15 46 29  2  9 53  9 71 29 37  7 27  1 19\n",
      " 16 44 65 71  8 45 37 68 20 39 47 40  0 16 35 72 47  8 65  8 59 12 20 46\n",
      " 71 53 53 55 65  9  0 22 25 45 16 52 23 18 21 59 25 70 11 65 14 32 48  6\n",
      " 39 69 65  6 10  4 53 22 70 20 11 71 71 65 65 57 22 70 71  7 46 53  8 71\n",
      " 18 46 62  0  8 19 18 13 44 10 39 42 13 60 47 42  2 20 46 25 18 39 18 25\n",
      " 47 32 10 25 35 69 13 11 47 60 46 60  9 51 70 32 54 10 18 12 26 41 18 34\n",
      "  0 54 21 52 60 62 55 35 11 41  7  4 14 31 46 69 53 56 32 15 49 18 72 40\n",
      " 21 53 11 55 43 15 12 54 32 65 11 44  7  3 53 25 61 34 57 72 72  9 49 35\n",
      "  7 66 39 44 23 40 41 70 15 65 72 11 21 57  8  4 35 54 29 10 15 31 20 20\n",
      " 33 70 20 68 71 62 46 37 18 60  2  6  0 16 53 38 20 61 71 13 60 48 46 48\n",
      " 68 15  4 68 22  9 32 60 47  9 53 47 21 51 56 48 53 53 16 69 49 57 46 45\n",
      " 53 18 60 46 41  6 65  8 25 12 39  8 53 60 45 71 68 29 23  7  1 62  0 10\n",
      " 55 11 15 10 48 53  7 55 15 15 45 25 60 69 53  6 34 61]\n",
      "0.3910761154855643\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForest(n_trees=800, max_deep=50)\n",
    "clf.fit(X_train, y_train.flatten())\n",
    "otv = clf.predict(X_test)\n",
    "# otv = np.argmax(clf.predict_proba(X_test), axis=1)\n",
    "print(otv)\n",
    "# print(y_test.flatten())\n",
    "print(f1_score(y_test.flatten() , otv, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 10, 14])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,1,1,1])\n",
    "\n",
    "W = np.array([[1,7,8,9],\n",
    "              [3,4,2,1],\n",
    "              [7,3,3,1]])\n",
    "x.dot(W.T) + "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
