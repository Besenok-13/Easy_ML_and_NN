{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Класс, который в последствии добавляется в словарь для удобного выбора\n",
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature=None,\n",
    "        threshold=None,\n",
    "        childs=None,\n",
    "        # left = None,\n",
    "        # right = None,\n",
    "        value=None,\n",
    "        proba_value = None\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.childs = childs\n",
    "        self.value = value\n",
    "        # self.right = right\n",
    "        # self.left = left\n",
    "        self.proba_value = proba_value\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "    \n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=10, min_samples=10):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        self.tree = None\n",
    "        self.classes = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "\n",
    "    def calck_unic(self, a: list):\n",
    "        keys = np.unique(a)\n",
    "        # return {key: a[a == key].shape[0] for key in keys}\n",
    "        return (a[a == key].shape[0] for key in keys), keys\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.travers_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return np.array([self.travers_proba_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def entropy(self, y: np.ndarray):\n",
    "        hist, _ = self.calck_unic(y)\n",
    "        n = y.shape[0]\n",
    "        # hist = {key: val / len(y) for key, val in hist.items()}\n",
    "        info = -np.sum(np.fromiter((val/n * np.log2(val/n) for val in hist), dtype=np.float64))\n",
    "\n",
    "        return info\n",
    "    \n",
    "    #======================================\n",
    "    def gini(self, y:np.ndarray):\n",
    "        uitems = self.calck_unic(y)\n",
    "        n = y.shape[0]\n",
    "        return 1 - np.sum(np.fromiter(((val/n)**2 for val in uitems), dtype=np.float64))\n",
    "    #======================================\n",
    "\n",
    "    def information_gain(self, X_column: list, y: list):\n",
    "        if np.unique(y).shape[0] == 1:\n",
    "            return 0\n",
    "\n",
    "        n = y.shape[0]\n",
    "        parent = self.entropy(y)\n",
    "        # print(\"point1\")\n",
    "        uitems, keys = self.calck_unic(X_column)\n",
    "        uitems = [i for i in uitems]\n",
    "        # print(\"point2\")\n",
    "        #======================================\n",
    "        # left_inds = np.argwhere(X_column <= threshold).flatten()\n",
    "        # right_inds = np.argwhere(X_column > threshold).flatten()\n",
    "        # # print(left_inds)\n",
    "        # # print(X_column.shape)\n",
    "        # # print(y.shape)\n",
    "        # gini_left = self.gini(y[left_inds])\n",
    "        # gini_right = self.gini(y[right_inds])\n",
    "        # gini_split = (len(left_inds) / n) * gini_left +  (len(right_inds) / n) * gini_right\n",
    "        # return gini_split, threshold\n",
    "        #====================================== \n",
    "        # print(X_column.shape, y.shape )\n",
    "        info_x = np.sum(\n",
    "            [uitems[i] / n * self.entropy(y[X_column == keys[i]]) for i in range(len(uitems))]\n",
    "        )\n",
    "        # print(\"point3\")\n",
    "        split_info = -np.sum(\n",
    "            [val / n * np.log2(val / n) for val in uitems if val > 0]\n",
    "        )\n",
    "        # print(\"point4\")\n",
    "        if split_info != 0:\n",
    "            return (parent - info_x) / split_info, keys\n",
    "        else:\n",
    "            return 0, keys\n",
    "\n",
    "    def most_common(self, y):\n",
    "        labels = np.unique(y)\n",
    "        vals, _ = self.calck_unic(y)\n",
    "        return labels[np.argmax(vals)]\n",
    "\n",
    "    def proba_val(self, y):\n",
    "        n = y.shape[0]\n",
    "        probas = np.zeros(self.classes.shape[0])\n",
    "        vals, keys = self.calck_unic(y)\n",
    "\n",
    "        probas[np.in1d(self.classes, keys)] = np.fromiter(vals, dtype=np.float64) / n\n",
    "        return probas\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        best_feature = None\n",
    "        best_gain = -1\n",
    "        # best_gini = 1000000\n",
    "        # uitems = []\n",
    "        for i in range(X.shape[1]):\n",
    "            #==============================================\n",
    "            # trasholds = np.random.choice(np.unique(X[:, i]), 10)\n",
    "            # print(\"new_i\")\n",
    "            # for trashold in trasholds:\n",
    "            #==============================================\n",
    "            # print(\"test1\")\n",
    "            gain, now_uitems = self.information_gain(X[:, i], y)\n",
    "            # print(\"test2\")\n",
    "            # print(gain)\n",
    "            if gain > best_gain:\n",
    "                # print(\"yep\")\n",
    "                best_gain = gain\n",
    "                best_feature = i\n",
    "                uitems = now_uitems\n",
    "\n",
    "        return best_feature, uitems\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        n_samples = X.shape[0]\n",
    "        n_labels = np.unique(y).shape[0]\n",
    "\n",
    "        if n_samples <= self.min_samples or depth >= self.max_depth or n_labels <= 1:\n",
    "            return Node(value=self.most_common(y), proba_value=self.proba_val(y))\n",
    "\n",
    "        best_feature, ukeys = self.best_split(X, y)\n",
    "        #==============================================\n",
    "        # best_feature, best_threshold = self.best_split(X, y)\n",
    "        # l_inds = np.argwhere(X[:, best_feature] <= best_threshold).flatten()\n",
    "        # r_inds = np.argwhere(X[:, best_feature] > best_threshold).flatten()\n",
    "        # # print(\"depth2:\", depth)\n",
    "        # if len(l_inds) == 0 or len(r_inds) == 0:\n",
    "        #     return Node(value=self.most_common(y), proba_valUe=self.proba_val(y))\n",
    "        \n",
    "        # # print(\"depth3:\", depth)\n",
    "        # left = self.grow_tree(X = X[l_inds], y = y[l_inds], depth = depth+1)\n",
    "        # right = self.grow_tree(X = X[r_inds], y = y[r_inds], depth = depth+1)\n",
    "\n",
    "        # return Node(best_feature, best_threshold, left, right)\n",
    "        #==============================================\n",
    "        # В словаре содержатся не словари, а Node По сути, словарь содержит ссылки на объекты, а нужен он для более удобной навигации.\n",
    "        childs = {\n",
    "            key: self.grow_tree(\n",
    "                X[X[:, best_feature] == key],\n",
    "                y[X[:, best_feature] == key],\n",
    "                depth=depth + 1,\n",
    "            )\n",
    "            for key in ukeys\n",
    "        }\n",
    "\n",
    "        return Node(best_feature, childs=childs)\n",
    "\n",
    "    #==============================================\n",
    "    # def travers_tree(self, x, tree):\n",
    "    #     if tree.is_leaf_node():\n",
    "    #         return tree.value\n",
    "        \n",
    "    #     return self.travers_tree(x, tree.left) if tree.threshold >= x[tree.feature] else self.travers_tree(x, tree.right)\n",
    "\n",
    "    # def travers_proba_tree(self, x, tree):\n",
    "    #     if tree.is_leaf_node():\n",
    "    #         # print(tree.proba_value)\n",
    "    #         return tree.proba_value\n",
    "        \n",
    "    #     return self.travers_proba_tree(x, tree.left) if tree.threshold >= x[tree.feature] else self.travers_proba_tree(x, tree.right)\n",
    "    #==============================================\n",
    "\n",
    "    def travers_tree(self, x, tree):\n",
    "        if tree.is_leaf_node():\n",
    "            return tree.value\n",
    "\n",
    "        return self.travers_tree(\n",
    "            x,\n",
    "            tree.childs.get(\n",
    "                x[tree.feature], tree.childs.get(list(tree.childs.keys())[0])\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def travers_proba_tree(self, x, tree):\n",
    "        if tree.is_leaf_node():\n",
    "            return tree.proba_value\n",
    "\n",
    "        return self.travers_proba_tree(\n",
    "            x,\n",
    "            tree.childs.get(\n",
    "                x[tree.feature], tree.childs.get(list(tree.childs.keys())[0])\n",
    "            ),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка данных\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "transform = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\n",
    "dataset[\"class\"] = dataset[\"class\"].apply(lambda x: transform[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data/X_train.csv\")\n",
    "data.drop(labels=\"measurement_number\", axis=1 , inplace=True)\n",
    "data = data.groupby(\"series_id\").agg(['mean', 'std', 'median'])\n",
    "data.columns = [f'{col}_{stat}' for col, stat in data.columns]\n",
    "data = data.reset_index()\n",
    "data.drop(labels=[\"series_id\",\"row_id_mean\",\"row_id_std\", \"row_id_median\"], axis=1 , inplace=True)\n",
    "data = data.round(2).to_numpy(dtype=np.float64)\n",
    "y = pd.read_csv(\"./Data/y_train.csv\")[\"group_id\"].to_numpy(dtype=np.int64)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "# print(np.unique(y_test))\n",
    "# data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 45  3 37 19 51 10 14  1 59 67 41 22 40 59 19 11 69 41 38 17 54 31 68\n",
      " 51 70 23 33 39 16 22 69 33 44 53  3 51 41 15 42 17 16 22 32  4  8 44 61\n",
      " 69 18 60 38 70 44 46 49 64 55 53 18 12  1 68 20  3 60 39 22 51  1 20 33\n",
      " 61  8 15 46 11 23 46 16  1 68 16 46 46 22 17 13 47 33 54 18  0  4 29 13\n",
      " 28  8 39 10 64 46 72 44 15  3 54 11 39 46  4 69 33 46  3 38 53 22 22 13\n",
      "  4 12 18 14  8  4 29 45 40 66 33 39  1  0  2 38 53 34  7 14 49 32  1 49\n",
      " 15 19 60 67 43 36 30 13  8 12  2 18 39  4 59 27 38 35  4 60 35 49 25 20\n",
      " 25 14 42 70  7 42 39 35 20 22 14 25 33  6 17 10 13 15 46 11 71 60 16 10\n",
      " 31 21 15 48  4 33  1 18  1 44 40 41 70 44 38  2  4 59 18 20 35  9 55 22\n",
      " 48 36 30 46 18 46 22 39 65 52 13 10 51 17 17 48 52 29 14 22 14 48 15  3\n",
      " 18 33 15 65 20 45 22 14 43  8  1 40 36  6 22 43 25  1  6 16 53 43 15  8\n",
      " 69 60 31 37 60 46 22 62  4 44 66 46 42 68 22 45 65  9 23 71 38  8 18  7\n",
      " 65 51 36 32 34 19  6 18 54 23 40 53 37 64 25 35 69 57 18 62  2 69 60 13\n",
      " 16  0 55  4 66 66 15 61 42 60 14 18 64 65 53 15 15 64 40 51  4 46 10 66\n",
      " 18 72 64  8  3 41 13 57 13 46  7 21 16 45 25 16 17 17 10 35 39 10 46  8\n",
      " 68 15  4 33 57 34 10 22 10  8 21 45 10 13 12 15 42  1 53  6  4 18 22 46\n",
      " 16 15  1 18 35  4 22 12  4 46 46 13 20 59 46 19 69 71 70 22 13 27  4 14\n",
      " 35 34 18 51 13 19 44 53 57  9 59 63  7 54 49 22 15 69  3 20 49 32 44 45\n",
      " 14  8 13 15 17 64  1 49 23 71 49 25 22 31 38  4 45 39 15 15 22 38 43  4\n",
      " 22 48 48 33 33  5  4 27 38 22 47 45  9 53 30 51  7 51 31  1 69 13 46 17\n",
      " 23 34 46 46 36  0 64 10 35 10 39  8 25 21 42 60 29  8 42  9 39 29 40 41\n",
      " 18 48 65 41  4 66 14 20 16 18 20 64 38  0 17  4 33  4 14  1 10 55 65 33\n",
      " 31 31 38 34  4 45 18 54 49 15 51  9 22 60  7  9 10 39 22 69 62 10  9 60\n",
      " 66 53  3 64 23 48 64 18 33 10 16 49 20 10 33  0 20 68 49 46 69  4 60 55\n",
      " 35 68 60 53 40 10 12  1 22 69  8 44 16 15 17 45 13 46 55 49  8 29 13 33\n",
      " 23 19 15 60 60 28 17  8 10  3 12 19 22  4 21 10 60 47 10  4 65  6 21 10\n",
      "  7 72 70 30 69 15 10 22 25 13 33 22 35  8 38 35 69 64 38 62 60 37  9 51\n",
      " 16 38  4 29 59 22 32 10 10  4 19 41 17  9  8 33 19 35 31 48 68 46 39 64\n",
      " 66 22 37 36 14 46 22 12 46 35 40 69 14  0 10 22 48 17  9 18 13 41 11  9\n",
      "  5 71 38 69 68 51 64 46 13 15  0 51 44 15 14 53 69 41 23 64 33 37  0 40\n",
      " 43  1 42 35 47  3 69 21  4  1 12 25 51 46 15 20 19 38 15 10 15 61 44 42\n",
      " 22 46 36 70  7  1 38 26 39 31 31 42  4 22  4 60 31 53]\n",
      "0.4553805774278215\n"
     ]
    }
   ],
   "source": [
    "# X = dataset[dataset.columns[:-1]].to_numpy()[:]\n",
    "# y = dataset[\"class\"].to_numpy()\n",
    "\n",
    "# x_train, x_test, y_train1, y_test1 = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2)\n",
    "clf = DecisionTree(max_depth=10)\n",
    "clf.fit(X_train, y_train.flatten())\n",
    "otv = clf.predict(X_test)\n",
    "print(otv)\n",
    "# print(y_test.flatten()-1)\n",
    "# print(X_test)\n",
    "print(f1_score(y_test.flatten(), otv, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees = 10, max_deep = 10, min_samples = 10):\n",
    "        self.trees = [0 for i in range(n_trees)]\n",
    "        self.tree_inds = [0 for i in range(n_trees)]\n",
    "        self.n_trees = n_trees\n",
    "        self.max_deep = max_deep\n",
    "        self.min_samples = min_samples\n",
    "        self.num_classes=None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_features = int(X.shape[1]**0.5+0.5)\n",
    "        # n_features = X.shape[0]\n",
    "        self.num_classes = np.unique(y).shape[0]\n",
    "\n",
    "        for i in range(self.n_trees):\n",
    "            clf = DecisionTree(max_depth=self.max_deep, min_samples=self.min_samples)\n",
    "            inds =  np.random.choice(np.arange(X.shape[1]), n_features)\n",
    "            # inds =  np.random.choice(np.arange(X.shape[0]), n_features, replace=True)\n",
    "            clf.fit(X[:, inds], y)\n",
    "            # print(y)\n",
    "            # clf.fit(X, y)\n",
    "            # print(clf.predict(x_test[:,inds ]))\n",
    "            self.trees[i] = clf\n",
    "            self.tree_inds[i] = inds\n",
    "    \n",
    "    def predict(self, X):\n",
    "        otv = np.zeros((X.shape[0], self.num_classes))\n",
    "        \n",
    "        for i, clf in enumerate(self.trees):\n",
    "            otv[np.arange(X.shape[0]), clf.predict(X[:, self.tree_inds[i]])] += 1\n",
    "            # otv[np.arange(X.shape[0]), clf.predict(X)] += 1\n",
    "            # print(otv)\n",
    "        # print(otv)\n",
    "        return np.argmax(otv, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        otv = np.zeros((X.shape[0], self.num_classes))\n",
    "        for i, clf in enumerate(self.trees):\n",
    "            otv += clf.predict_proba(X[:, self.tree_inds[i]])\n",
    "\n",
    "        return otv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 16  3 37 15 61 49 14 11 59 67 41 32 18 59 72 11 56 41 25 57 48 31 68\n",
      " 51 70 23 60 39 16  0 69 33 21 70  3 61 41 25 72 57 16 22 20  2 60 36 22\n",
      " 69 26 71 59 70 44 26 51 64 66 64 40 12  9 22 45 26 71 39 22 61  1 62 33\n",
      " 51  8 55  3 11 23  3 49 47 68 16 61 61  0  1 30 47 33 48 72 68 47 29 13\n",
      " 35 28 72 52 64 26 72 47 72  3 48 11 40 51  4 56 33  3  3 40 15  0  4 13\n",
      "  4 12 42 15  8  4 29 45 45 71 60 70 29 68 46 27 53 34  7 14 43 61 11 13\n",
      " 54 19 60 67 42 36 34 13  8 12 65 18 63 41 59 13 42 69  4 71 69 68 25  0\n",
      " 25 64 42 70 10 72 70 27  7  7 14 25 33 29 57  7 12 43 26 11 66 66 16 10\n",
      " 31 21 55 48  4 60  9 18 56 59 69 41 70 36 45 44  4 59  9 68 35 27 71  0\n",
      " 48 36 34 26 42 27 22 55 65 14 34 31 51 21 57 15 52 41 14 22 14 48 23  3\n",
      " 38 33 23 61 20 22  0 52 70 49  9 59 36  9 22 43 25 43  6 16 53 62 49  8\n",
      " 69 71 22 69 45  3  7 62  9 59 66 26 42 68 32 46 50 21 23 71 43 38 42 22\n",
      " 20 68 36 32 34 19  6 42 14 23 40 53 69 64 25 69 69 57 18 62  2 69 71 13\n",
      " 62 68 44 44 66 66 15 22 70 66 14 18 64 61 54 25 67 64 59 51 36 61 22 66\n",
      " 43 42 48 28  3 41 13 57 62 46 13 21 16 46 25 16 57 21 22 35 59 22 51 27\n",
      " 68 55 36 33 57 34 13  7 31 28 21 49 39 13 12 23 19  1 54  6  4 18 22 51\n",
      " 45 34 43  9 35 41 32 12  4 51 51 13 62 59 46 15 69 71 70 22 13 44 41 19\n",
      " 35 34 18 10 13 72 44 53 57  9 59 39 31 15 39  0 15 37 26  7 51  0 44 46\n",
      " 53  8 16 54 47 53 11 70 23 71 23 25 32 31 42  4 49 70 21 49  0 16 69 36\n",
      "  0 48 48 33 33 28  4 27 45 50 47 60 38 15 34 51 62 22 31 44 69 13 42 47\n",
      " 23 34 22 26 36 20 64 49 35 45 59 21 25 21 72 71 29  8 42  9 72 29 38 41\n",
      " 18 39 65 41 11 66 15 31 16 68  0 53 21 32  1 11 33  4 14 29 31 71 70 33\n",
      " 31 31 16 34 47 13 19 48 61 55 51  9  7 60 46 11 31 72 20 69 61 22 11 66\n",
      " 71 54  3 64 23 15 64 44 60 10 62 46 12 31 33 61 62 68 51 46 56  4 60 55\n",
      " 35 68 60 53 43 31 12 11 22 69 60 44 10 25 47 45 13 22 55 51 28 29 13 35\n",
      " 23 72 49 60 60  8 11  8 39  3 20 19 22  4 21 23 71 68 16  4 65  6 21 23\n",
      " 31 72 70 30 69 54 45 22 25 13 35 22 21  8 25 35 69 64 45 49 60 69 57 51\n",
      " 45 14  4 29 59  0 32 10 45 36 19 41  1  9  8 35 19 35 22 48 68  3 43 53\n",
      " 66 10 37 36 19 61 22 12 60 46 59 69 52 20 22 22 15 57  9 26 13 41 11  9\n",
      "  8 71  9 69 68 61 64 51 34 55 32 46  9 25 14 54 69 41 23 53 33 69 20 45\n",
      " 69 11 42 60 47 29 56 21 44  1 12 25 20  3 55 68 67 38 15 39 54 61 21 42\n",
      " 22 31 36 70 31  1 38  3 39 31 31 43  4  0  6 66 31 15]\n",
      "0.5249343832020997\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForest(n_trees=800, max_deep=100)\n",
    "clf.fit(X_train, y_train.flatten())\n",
    "# otv = clf.predict(X_test)\n",
    "otv = np.argmax(clf.predict_proba(X_test), axis=1)\n",
    "print(otv)\n",
    "# print(y_test.flatten())\n",
    "print(f1_score(y_test.flatten() , otv, average=\"micro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
