{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка данных\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = pd.read_csv(url, names=names)\n",
    "transform = {'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2}\n",
    "dataset[\"class\"] = dataset[\"class\"].apply(lambda x: transform[x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "X_train = pd.read_csv(\"./UCI HAR Dataset/train/X_train.txt\", sep=\",\", names=[i for i in range(0,561)]).to_numpy()\n",
    "X_test = pd.read_csv(\"./UCI HAR Dataset/test/X_test.txt\", sep=\",\", names=[i for i in range(0,561)]).to_numpy()\n",
    "y_train = pd.read_csv(\"./UCI HAR Dataset/train/y_train.txt\", names=[\"Y\"]).to_numpy()\n",
    "y_test = pd.read_csv(\"./UCI HAR Dataset/test/y_test.txt\", names=[\"Y\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Класс, который в последствии добавляется в словарь для удобного выбора\n",
    "class Node:\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature=None,\n",
    "        threshold=None,\n",
    "        # childs=None,\n",
    "        left = None,\n",
    "        right = None,\n",
    "        value=None\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        # self.childs = childs\n",
    "        self.value = value\n",
    "        self.right = right\n",
    "        self.left = left\n",
    "\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "    \n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=10, min_samples=10):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        self.tree = None\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.grow_tree(X, y)\n",
    "\n",
    "    def calck_unic(self, a: list):\n",
    "        keys = np.unique(a)\n",
    "        # return {key: a[a == key].shape[0] for key in keys}\n",
    "        return (a[a == key].shape[0] for key in keys)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.travers_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def entropy(self, y: np.ndarray):\n",
    "        hist = self.calck_unic(y)\n",
    "        n = y.shape[0]\n",
    "        # hist = {key: val / len(y) for key, val in hist.items()}\n",
    "        info = -np.sum(np.fromiter((val/n * np.log2(val/n) for val in hist), dtype=np.float32))\n",
    "\n",
    "        return info\n",
    "    \n",
    "    #======================================\n",
    "    def gini(self, y:np.ndarray):\n",
    "        uitems = self.calck_unic(y)\n",
    "        n = y.shape[0]\n",
    "        return 1 - np.sum(np.fromiter(((val/n)**2 for val in uitems), dtype=np.float32))\n",
    "    #======================================\n",
    "\n",
    "    def information_gain(self, X_column: list, y: list, threshold:float):\n",
    "        if np.unique(y).shape[0] == 1:\n",
    "            return 0\n",
    "\n",
    "        n = y.shape[0]\n",
    "        # info(T)\n",
    "        # parent = self.entropy(y)\n",
    "        # uitems = self.calck_unic(X_column)\n",
    "        #======================================\n",
    "        left_inds = np.argwhere(X_column <= threshold).flatten()\n",
    "        right_inds = np.argwhere(X_column > threshold).flatten()\n",
    "        # print(left_inds)\n",
    "        # print(X_column.shape)\n",
    "        # print(y.shape)\n",
    "        gini_left = self.gini(y[left_inds])\n",
    "        gini_right = self.gini(y[right_inds])\n",
    "        gini_split = (len(left_inds) / n) * gini_left +  (len(right_inds) / n) * gini_right\n",
    "        return gini_split, threshold\n",
    "        #====================================== \n",
    "        # info_x = np.sum(\n",
    "        #     [val / n * self.entropy(y[X_column == key]) for key, val in uitems.items()]\n",
    "        # )\n",
    "        # split_info = -np.sum(\n",
    "        #     val / n * np.log2(val / n) for val in uitems.values() if val > 0\n",
    "        # )\n",
    "        # if split_info != 0:\n",
    "        #     return (parent - info_x) / split_info, list(uitems.keys())\n",
    "        # else:\n",
    "        #     return 0, list(uitems.keys())\n",
    "\n",
    "    def most_common(self, y):\n",
    "        labels = np.unique(y)\n",
    "        vals = self.calck_unic(y)\n",
    "        return labels[np.argmax(vals)]\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        best_feature, best_threshold = None, None\n",
    "        # best_gain = -1\n",
    "        best_gini = 1000000\n",
    "        # uitems = []\n",
    "        for i in range(X.shape[1]):\n",
    "            #==============================================\n",
    "            trasholds = np.random.choice(np.unique(X[:, i]), 10)\n",
    "            # print(\"new_i\")\n",
    "            for trashold in trasholds:\n",
    "            #==============================================\n",
    "                gini, threshold = self.information_gain(X[:, i], y, trashold)\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feature = i\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def grow_tree(self, X, y, depth=0):\n",
    "        n_samples = X.shape[0]\n",
    "        n_labels = np.unique(y).shape[0]\n",
    "        # print(\"depth1:\", depth)\n",
    "        if n_samples <= self.min_samples or depth >= self.max_depth or n_labels <= 1:\n",
    "            return Node(value=self.most_common(y))\n",
    "\n",
    "        #==============================================\n",
    "        best_feature, best_threshold = self.best_split(X, y)\n",
    "        l_inds = np.argwhere(X[:, best_feature] <= best_threshold).flatten()\n",
    "        r_inds = np.argwhere(X[:, best_feature] > best_threshold).flatten()\n",
    "        # print(\"depth2:\", depth)\n",
    "        if len(l_inds) == 0 or len(r_inds) == 0:\n",
    "            return Node(value=self.most_common(y))\n",
    "        \n",
    "        # print(\"depth3:\", depth)\n",
    "        left = self.grow_tree(X = X[l_inds], y = y[l_inds], depth = depth+1)\n",
    "        right = self.grow_tree(X = X[r_inds], y = y[r_inds], depth = depth+1)\n",
    "\n",
    "        return Node(best_feature, best_threshold, left, right)\n",
    "        #==============================================\n",
    "\n",
    "        # В словаре содержатся не словари, а Node По сути, словарь содержит ссылки на объекты, а нужен он для более удобной навигации.\n",
    "        # childs = {\n",
    "        #     key: self.grow_tree(\n",
    "        #         X[X[:, best_feature] == key],\n",
    "        #         y[X[:, best_feature] == key],\n",
    "        #         depth=depth + 1,\n",
    "        #     )\n",
    "        #     for key in ukeys\n",
    "        # }\n",
    "\n",
    "        # return Node(best_feature, childs=childs)\n",
    "\n",
    "    #==============================================\n",
    "    def travers_tree(self, x, tree):\n",
    "        if tree.is_leaf_node():\n",
    "            return tree.value\n",
    "        \n",
    "        return self.travers_tree(x, tree.left) if tree.threshold >= x[tree.feature] else self.travers_tree(x, tree.right)\n",
    "    #==============================================\n",
    "\n",
    "    # def travers_tree(self, x, tree):\n",
    "    #     if tree.is_leaf_node():\n",
    "    #         return tree.value\n",
    "\n",
    "    #     return self.travers_tree(\n",
    "    #         x,\n",
    "    #         tree.childs.get(\n",
    "    #             x[tree.feature], tree.childs.get(list(tree.childs.keys())[0])\n",
    "    #         ),\n",
    "    #     )\n",
    "\n",
    "\n",
    "def preload():\n",
    "    df = pd.read_csv(\"agaricus-lepiota.csv\")\n",
    "    y = np.array(df.pop(\"poison\"))\n",
    "\n",
    "    n = df.shape[1]\n",
    "    to_del = int(n ** 0.5)\n",
    "    import random\n",
    "\n",
    "    for i in range(n - to_del - 1):\n",
    "        df.pop(random.choice(df.columns))\n",
    "    x = np.array(df)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def acc_pre_rec(otv, y):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for i in range(len(otv)):\n",
    "        if otv[i] == \"p\" and y[i] == \"p\":\n",
    "            tp += 1\n",
    "        elif otv[i] == \"p\" and y[i] == \"e\":\n",
    "            fp += 1\n",
    "        elif otv[i] == \"e\" and y[i] == \"p\":\n",
    "            fn += 1\n",
    "        elif otv[i] == \"e\" and y[i] == \"e\":\n",
    "            tn += 1\n",
    "\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    pre = tp / max((tp + fp), 1)\n",
    "    rec = tp / max(tp + fn, 1)\n",
    "    fpr = fp / max(tn + fp, 1)\n",
    "\n",
    "    return acc, pre, rec, fpr\n",
    "\n",
    "# x, y = preload()\n",
    "# print(len(y))\n",
    "\n",
    "\n",
    "# x = dataset[dataset.columns[:-1]].to_numpy()[:, :2]\n",
    "# y = dataset[\"class\"].to_numpy()\n",
    "\n",
    "\n",
    "# clf = DecisionTree(max_depth=2)\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)\n",
    "# clf.fit(x_train, y_train)\n",
    "\n",
    "# otv = clf.predict(x_test)\n",
    "\n",
    "# print(f1_score(y_test, otv, average=\"micro\"))\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, shuffle=True)\n",
    "# clf.fit(x_train, y_train)\n",
    "\n",
    "# otv = clf.predict(x_test)\n",
    "# acc, pre, rec, fpr = acc_pre_rec(y_test, otv)\n",
    "# print(f\"accuracy: {acc}\")\n",
    "# print(f\"precision: {pre}\")\n",
    "# print(f\"recall: {rec} \")\n",
    "\n",
    "# points = np.array([[0, 0], [fpr, rec], [1, 1]])\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12, 7))\n",
    "\n",
    "# plt.plot(\n",
    "#     points[:, 0],\n",
    "#     points[:, 1],\n",
    "#     \"o-r\",\n",
    "#     alpha=0.7,\n",
    "#     label=\"first\",\n",
    "#     lw=5,\n",
    "#     mec=\"b\",\n",
    "#     mew=2,\n",
    "#     ms=10,\n",
    "# )\n",
    "# plt.fill_between(points[:, 0],\n",
    "#     points[:, 1], where=None, interpolate=False, step=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "    def __init__(self, learning_rate=0.2, n_estimators=100, max_depth=3):\n",
    "        \"\"\"\n",
    "        :param learning_rate: скорость обучения\n",
    "        :param n_estimators: количество деревьев\n",
    "        :param max_depth: максимальная глубина деревьев\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.num_classes = None\n",
    "        self.base_estimators = []\n",
    "        \n",
    "    def sigmoid(self, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_pred: прогноз модели\n",
    "        :return: значение функции сигмоиды для прогноза\n",
    "        \"\"\"\n",
    "        return 1.0 / (1.0 + np.exp(-y_pred))\n",
    "    \n",
    "    def softmax(self, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_pred: прогноз модели\n",
    "        :return: значение функции softmax для прогноза\n",
    "        \"\"\"\n",
    "        exp_pred = np.exp(y_pred)\n",
    "        return exp_pred / np.sum(exp_pred, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    def logloss_gradient(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: истинный ответ\n",
    "        :param y_pred: прогноз модели\n",
    "        :return: значение градиента функции потерь logLoss\n",
    "        \"\"\"\n",
    "        # p = self.softmax(y_pred)\n",
    "        return (y_pred - y_true) / y_true.shape[0]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучение градиентного бустинга с OneVsAll методом.\n",
    "        :param X: матрица объектов (numpy array)\n",
    "        :param y: вектор истинных ответов (numpy array)\n",
    "        \"\"\"\n",
    "        self.num_classes = np.unique(y).shape[0]\n",
    "\n",
    "        for k in range(self.num_classes):\n",
    "            y_k = np.where(y == k, 1, 0)\n",
    "            # print(y_k)\n",
    "            # print(y_k)\n",
    "            # print(y)\n",
    "            y_pred = np.zeros_like(y_k, dtype=np.float64)\n",
    "            estimator = DecisionTree(max_depth=self.max_depth)\n",
    "            estimator.fit(X, y_k)\n",
    "            y_pred += estimator.predict(X)\n",
    "            self.base_estimators.append((estimator, k))\n",
    "            # print(y_pred)\n",
    "            for m in range(self.n_estimators - 1):\n",
    "                grad = self.logloss_gradient(y_k, y_pred)\n",
    "                # print(grad)\n",
    "                estimator = DecisionTree(max_depth=self.max_depth)\n",
    "                # Идём в сторону АНТИГРАДИЕНТА БЛИН, АН-ТИ ГРАДИЕНТА (-2 часа в попытках найти баг в дереве)\n",
    "                estimator.fit(X, -grad)\n",
    "                self.base_estimators.append((estimator, k))\n",
    "                otv = estimator.predict(X)\n",
    "                y_pred += self.learning_rate * otv\n",
    "                \n",
    "                \n",
    "    def predict_proba(self, X, class_check:int = None):\n",
    "        \"\"\"\n",
    "        Предсказание вероятности класса.\n",
    "        \"\"\"\n",
    "        if not class_check:\n",
    "            y_pred_proba = np.zeros((X.shape[0], self.num_classes))\n",
    "        else:\n",
    "            y_pred_proba = np.zeros((X.shape[0], 2))\n",
    "\n",
    "        # print(y_pred_proba)\n",
    "        for m in range(self.n_estimators):\n",
    "            flag = 1\n",
    "\n",
    "            for estimator, k in self.base_estimators:\n",
    "                if not class_check:\n",
    "                    y_pred_proba[:, k] += flag * estimator.predict(X)\n",
    "                elif k == class_check:\n",
    "                    y_pred_proba[:, 1] += flag * estimator.predict(X)\n",
    "\n",
    "                flag = self.learning_rate\n",
    "                    \n",
    "\n",
    "        return self.softmax(y_pred_proba)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание класса.\n",
    "        \"\"\"\n",
    "        y_pred_proba = self.predict_proba(X)\n",
    "        return np.argmax(y_pred_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 1 1 0 0 2 1 2 0 0 0 2 1 0 2 0 0 0 0 1 1 0 1 0 2 1]\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "X = dataset[dataset.columns[:-1]].to_numpy()[:, [1,3]]\n",
    "y = dataset[\"class\"].to_numpy()\n",
    "\n",
    "x_train, x_text, y_train1, y_test1 = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "clf = GradientBoosting(max_depth=2, n_estimators=100)\n",
    "# cols = np.array([1,2,3, 41, 42, 43, 81, 82, 83, 121, 122, 123, 161, 162, 163]) - 1\n",
    "# clf.fit(X_train[:,:10], y_train.flatten() -1 )\n",
    "clf.fit(x_train, y_train1 )\n",
    "\n",
    "otv = clf.predict(x_text)\n",
    "print(otv)\n",
    "print(f1_score(y_test1 , otv, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.55670315e-04, 9.99488659e-01, 2.55670315e-04],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [3.33333333e-01, 3.33333333e-01, 3.33333333e-01],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [1.14183646e-21, 1.14183646e-21, 1.00000000e+00],\n",
       "       [1.14183646e-21, 1.14183646e-21, 1.00000000e+00],\n",
       "       [2.28875228e-22, 2.28875228e-22, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [3.33333333e-01, 3.33333333e-01, 3.33333333e-01],\n",
       "       [3.33333333e-01, 3.33333333e-01, 3.33333333e-01],\n",
       "       [1.14183646e-21, 1.14183646e-21, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [1.47687904e-01, 1.47687904e-01, 7.04624193e-01],\n",
       "       [2.55670315e-04, 9.99488659e-01, 2.55670315e-04],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [3.33333333e-01, 3.33333333e-01, 3.33333333e-01],\n",
       "       [3.33333333e-01, 3.33333333e-01, 3.33333333e-01],\n",
       "       [2.55670315e-04, 9.99488659e-01, 2.55670315e-04],\n",
       "       [1.47687904e-01, 1.47687904e-01, 7.04624193e-01],\n",
       "       [5.37262785e-09, 5.37262785e-09, 9.99999989e-01],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [2.39326771e-22, 2.39326771e-22, 1.00000000e+00],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [2.55670315e-04, 9.99488659e-01, 2.55670315e-04],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [1.00000000e+00, 3.72007598e-44, 3.72007598e-44],\n",
       "       [3.33333333e-01, 3.33333333e-01, 3.33333333e-01],\n",
       "       [2.39326771e-22, 2.39326771e-22, 1.00000000e+00]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(x_text)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 0 1 2 0 0 1 2 2 1 0 1 1 2 0 1 2 2 1 1 1 1 2 1 1 0]\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTree(max_depth=2)\n",
    "clf.fit(x_train, y_train1)\n",
    "\n",
    "otv = clf.predict(x_text)\n",
    "# otv_prob = clf.predict_proba(x_text)\n",
    "print(otv)\n",
    "print(f1_score(y_test1.flatten(), otv, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC_ROC_One_vs_all(y_true, y_pred_proba):\n",
    "    y_true1, y_pred_proba_1 = list(zip(*list(sorted(zip(y_true, y_pred_proba), key = lambda x : x[1]))))\n",
    "    print(y_true1)\n",
    "    print(y_pred_proba_1)\n",
    "\n",
    "    y_pred_proba_1 = np.where(y_pred_proba_1 > 0.5, 1, 0)\n",
    "    for i in range(len(y_pred_proba_1)):\n",
    "        if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m AUC_ROC_One_vs_all(np\u001b[39m.\u001b[39;49marray[\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m], np\u001b[39m.\u001b[39marray[\u001b[39m0.1\u001b[39m, \u001b[39m0.7\u001b[39m, \u001b[39m0.8\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0\u001b[39m,\u001b[39m3\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "AUC_ROC_One_vs_all(np.array[1,2,3,0,-1,-2], np.array[0.1, 0.7, 0.8, 0.2, 0,3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
